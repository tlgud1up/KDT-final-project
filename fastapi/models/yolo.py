"""
yolov8_model.py

    ì´ íŒŒì¼ì€ YOLOv8 ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ë¡œë“œí•˜ê³ ,
    FastAPIì˜ main.pyì—ì„œ ì´ë¯¸ì§€ë¥¼ ì „ë‹¬ë°›ì•„ ëª¨ë¸ ì¶”ë¡ ì„ ìˆ˜í–‰í•œ ë’¤,
    ê°ì²´ë³„ 'ê°ì§€ ê°œìˆ˜'ì™€ 'í™”ë©´ ë‚´ ì‹¤ì œ ë©´ì  ë¹„ìœ¨(%)'ì„ ê³„ì‚°í•´ ë°˜í™˜í•©ë‹ˆë‹¤.

- ëª¨ë¸ ë¡œë“œëŠ” ì„œë²„ ì‹œì‘ ì‹œ ë‹¨ 1íšŒë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
- ì¶”ë¡ ì€ run_inference(image_path) í•¨ìˆ˜ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
"""


# ================ ê²€ì¶œ ë¹„ìœ¨ ìˆ˜ì •!!!!!!!!!!!!!!!!!!! ë²„ì „ ================
from ultralytics import YOLO
import cv2, base64, os, numpy as np
import math

# ğŸ¨ í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì •ì˜ (BGR)
CLASS_COLORS = {
    0: (0, 150, 15),   # ë‚˜ë¬´ (ì´ˆë¡)
    1: (245, 35, 0),  # ë¹„ë‹ (íŒŒë‘)
    2: (38, 38, 245)  # í”Œë¼ìŠ¤í‹± (ë¹¨ê°•)
}

ALPHA = 0.3  # ë§ˆìŠ¤í¬ íˆ¬ëª…ë„



# ğŸ”· ê³ ì •ëœ ì‹¤ì œ ë°”ë‹¥ ì „ì²´ ë©´ì  (10m ë†’ì´, FOV 60Â° x 45Â° ê¸°ì¤€)
# ê³„ì‚°ì‹: ë°”ë‹¥ë©´ì  = (2 * H * tan(HFOV/2)) * (2 * H * tan(VFOV/2))
# => ì•½ 95.6mÂ²
TOTAL_REAL_WORLD_AREA = 95.6  # ê³ ì • ìƒìˆ˜ (mÂ²)


class YOLOWrapper:
    def __init__(self, weight_path):
        self.model = YOLO(weight_path)
        self.names = self.model.names
        print(f"\n[YOLO] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        # ğŸ”· ì´¬ì˜ ì¡°ê±´ì— ê¸°ë°˜í•œ ì‹¤ì œ ë°”ë‹¥ ì „ì²´ ë©´ì  (ê³ ì •ê°’)
        self.total_real_world_area = self._calculate_ground_area(fov_h=60, fov_v=45, height=10)

    def _calculate_ground_area(self, fov_h, fov_v, height):
        """
        ì¹´ë©”ë¼ í™”ê°ê³¼ ì´¬ì˜ ë†’ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ë°”ë‹¥ì˜ ì „ì²´ ì´¬ì˜ ë©´ì (mÂ²)ì„ ê³„ì‚°
        """
        width_m = 2 * height * math.tan(math.radians(fov_h / 2))
        height_m = 2 * height * math.tan(math.radians(fov_v / 2))
        area = width_m * height_m
        return round(area, 2)  # 95.6mÂ² ì²˜ëŸ¼ ì •ë¦¬ëœ ê°’ ë°˜í™˜

    def _calculate_object_area(self, object_pixels, total_pixels):
        """
        YOLO segmentation maskì—ì„œ ì–»ì€ í”½ì…€ ìˆ˜ë¥¼ ì‹¤ì œ ë©´ì (mÂ²)ê³¼ ë¹„ìœ¨(%)ë¡œ ë³€í™˜
        """
        if total_pixels == 0 or object_pixels == 0:
            return 0.0, 0.0

        pixel_ratio = object_pixels / total_pixels
        real_area = self.total_real_world_area * pixel_ratio
        percent = pixel_ratio * 100
        return round(real_area, 2), round(percent, 2)


    def predict(self, image_path):
        # YOLO ì¶”ë¡  ì‹¤í–‰
        result = self.model.predict(
            source=image_path, conf=0.5, show=False, show_boxes=False, save=False
        )[0]

        img_h, img_w = result.orig_shape
        total_pixels = img_h * img_w  # ì „ì²´ í”½ì…€ ìˆ˜ (1920x1080)

        # ë¹„ìœ¨ ë° ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
        ratios = {"plastic": 0.0, "vinyl": 0.0, "wood": 0.0}
        real_areas = {"plastic": 0.0, "vinyl": 0.0, "wood": 0.0}
        count = 0

        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)

        if result.masks is not None:
            for mask, box, cls_id in zip(result.masks.data, result.boxes.xyxy, result.boxes.cls):
                mask_np = mask.cpu().numpy()
                mask_resized = cv2.resize(mask_np, (image.shape[1], image.shape[0]))

                class_name = self.names[int(cls_id)]
                color = CLASS_COLORS.get(int(cls_id), (255, 255, 255))

                # ğŸ”· í”½ì…€ ê¸°ë°˜ ë©´ì  ê³„ì‚° í˜¸ì¶œ
                object_pixels = np.sum(mask_resized > 0.5)
                real_area, percent = self._calculate_object_area(object_pixels, total_pixels)

                # í†µí•© ì €ì¥
                if class_name in ratios:
                    ratios[class_name] += percent
                    real_areas[class_name] += real_area

                # # ì‹œê°í™”
                # mask_img = np.zeros_like(image, dtype=np.uint8)
                # mask_img[mask_resized > 0.5] = color
                # image = cv2.addWeighted(mask_img, ALPHA, image, 1 - ALPHA, 0)

                # ì‹œê°í™” (ë°ê¸° ì–´ë‘ì› ë˜ ë¬¸ì œ í•´ê²°)
                overlay = image.copy()
                overlay[mask_resized > 0.5] = color
                image = cv2.addWeighted(overlay, 0.4, image, 0.6, 0)

                # x1, y1, x2, y2 = map(int, box)
                # cv2.putText(image, f"{class_name}", (x1, y1 - 5),
                #             cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                # ===== ë¼ë²¨ í¬ê¸° í‚¤ìš°ê¸°
                # === ë¼ë²¨ ê·¸ë¦¬ê¸° (í¬ê²Œ + ê°€ë…ì„± ë†’ì„) ===
                # ë¼ë²¨ í‘œì‹œ (ê°ì²´ ìƒ‰ ê·¸ëŒ€ë¡œ, í¬ê¸°ë§Œ í™•ëŒ€)
                x1, y1, x2, y2 = map(int, box)

                # ê°ì²´ í¬ê¸°ì— ë¹„ë¡€í•œ ê¸€ì”¨ í¬ê¸° ìë™ ì¡°ì • (ë„ˆë¬´ ì‘ì„ ë•Œ ëŒ€ë¹„)
                font_scale = max(0.8, min(2.5, (y2 - y1) / 80.0))
                thickness = max(2, int(font_scale * 2))

                label = f"{class_name}"
                cv2.putText(image, label, (x1, max(20, y1 - 10)),
                            cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 10)
                # =====

                count += 1

        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        os.makedirs("temp", exist_ok=True)
        result_image_path = f"temp/result_{os.path.basename(image_path)}"
        cv2.imwrite(result_image_path, image)

        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë³€í™˜
        with open(result_image_path, "rb") as f:
            result_img_base64 = base64.b64encode(f.read()).decode("utf-8")

        # ì…ë ¥ëœ ì›ë³¸ ì´ë¯¸ì§€ë„ Base64 ë³€í™˜
        with open(image_path, "rb") as f:
            orig_img_base64 = base64.b64encode(f.read()).decode("utf-8")


        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        return {
            "orig_img": orig_img_base64,      # Base64 ì›ë³¸ ì´ë¯¸ì§€
            "rcnn_result": result_img_base64, # Base64 ê²°ê³¼ ì´ë¯¸ì§€
            "wood": round(ratios["wood"], 2),
            "plastic": round(ratios["plastic"], 2),
            "vinyl": round(ratios["vinyl"], 2),
            "count": count
        }


# ê²€ì¶œ ë©´ì  ê³„ì‚° ê·¼ê±°
# ì´¬ì˜ ë†’ì´(H), í™”ê°(HFOV/VFOV)ì´ ê³ ì •ì´ë¼ë©´ â†’ ë°”ë‹¥ ë©´ì ì€ "í•­ìƒ ë™ì¼"í•œ ê³ ì •ê°’
# ì¦‰, 95.6mÂ²ëŠ” ê³ ì •ëœ ìƒìˆ˜ ê°’ìœ¼ë¡œ ê°„ì£¼í•  ìˆ˜ ìˆê³ , ì½”ë“œì—ì„œ ë§¤ë²ˆ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
# ë°”ë‹¥ë©´ì  S = 2 * H * tan(HFOV / 2) * 2 * H * tan(VFOV / 2) = 95.6mÂ²
# â€œ1920Ã—1080 í•´ìƒë„ëŠ” ë°”ë‹¥ ë©´ì  ê³„ì‚°ì— ì§ì ‘ì ìœ¼ë¡œ ì“°ì´ì§€ ì•ŠëŠ”ë‹¤â€ëŠ” ì ì„ ì´í•´í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.
# í•´ìƒë„ëŠ” â€œë°”ë‹¥ ë©´ì ì´ ì•„ë‹Œ ë°”ë‹¥ ë©´ì ì„ ë‚˜ëˆ„ëŠ” ë¶„í•´ëŠ¥â€


# ê°œë… ì •ë¦¬
# ì´¬ì˜ ë†’ì´ + í™”ê° : ì¹´ë©”ë¼ê°€ ì‹¤ì œë¡œ ë³¼ ìˆ˜ ìˆëŠ” ê³µê°„ì˜ í¬ê¸°	â†’ ì „ì²´ ë°”ë‹¥ ë©´ì (mÂ²)ì„ ê²°ì •
# 1920Ã—1080 í•´ìƒë„ : ê·¸ ê³µê°„ì„ ëª‡ ê°œì˜ í”½ì…€ë¡œ ë‚˜ëˆ ì„œ í‘œí˜„í•˜ëŠ”ì§€	â†’ í”½ì…€ë‹¹ ì‹¤ì œ ë©´ì  ê³„ì‚°ì— ì‚¬ìš©


# ê³„ì‚° íë¦„
# [ì‹¤ì œ ë°”ë‹¥ ì „ì²´ ë©´ì  95.6mÂ²]
#      â†“ í•´ìƒë„ 1920Ã—1080ì— ì˜í•´ í”½ì…€ë¡œ ë¶„í• 
# [2,073,600 í”½ì…€]
#      â†“ YOLOê°€ ë§ˆìŠ¤í¬ ì²˜ë¦¬ë¡œ íŠ¹ì • ê°ì²´ ì˜ì—­ í”½ì…€ ìˆ˜ ê³„ì‚°
# [ì˜ˆ: object_pixels = 200,000]
#      â†“ í”½ì…€ ë¹„ìœ¨
# pixel_ratio = 200,000 / 2,073,600 â‰ˆ 0.096
#      â†“ ì‹¤ì œ ë©´ì  ê³„ì‚°
# object_real_area = 95.6mÂ² * 0.096 â‰ˆ 9.18mÂ²


# ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    weight_path = "../weights/best.pt"
    image_path = "C:/Users/301/Desktop/create_image/image_4.png"

    yolo = YOLOWrapper(weight_path)
    result = yolo.predict(image_path)

    print("\n========== ğŸ” ë¶„ì„ ê²°ê³¼ ==========")
    print(f"[YOLO] ì´ ê°ì§€ ê°ì²´ ìˆ˜: {result['count']}")
    print(f"[YOLO] ë‚˜ë¬´ ë¹„ìœ¨: {result['wood']}%")
    print(f"[YOLO] í”Œë¼ìŠ¤í‹± ë¹„ìœ¨: {result['plastic']}%")
    print(f"[YOLO] ë¹„ë‹ ë¹„ìœ¨: {result['vinyl']}%")
    print("==================================\n")

    # âœ… Base64 â†’ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
    decoded = base64.b64decode(result['rcnn_result'])
    np_img = np.frombuffer(decoded, np.uint8)
    final_img = cv2.imdecode(np_img, cv2.IMREAD_COLOR)

    cv2.imshow("YOLO Detection Result", final_img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()