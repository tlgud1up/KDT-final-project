import os
import numpy as np
import joblib
import cv2
from sklearn.preprocessing import StandardScaler
from ultralytics import YOLO
from sklearn.decomposition import PCA

# https://doing-nothing.tistory.com/79 pca ë¶„ì„ ì •ê·œí™” ê³¼ì • ì°¸ê³ 

# ë³¸ ì½”ë“œëŠ” YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼(ë§ˆìŠ¤í¬ í”½ì…€ ìˆ˜)ë¥¼ ì´ë¯¸ì§€ ì „ì²´ í”½ì…€ ìˆ˜ë¡œ ë‚˜ëˆ 
# í´ë˜ìŠ¤ë³„ 'ë©´ì  ë¹„ìœ¨(feature)'ì„ ë§Œë“  ë’¤, ì´ë¥¼ í‘œì¤€í™” â†’ PCA(2ì°¨ì›)ë¡œ ì¶•ì†Œí•˜ê³ 
# ëª¨ë¸(Scaler, PCA)ê³¼ ì¤‘ê°„ ê²°ê³¼(features ë“±)ì„ ì €ì¥í•©ë‹ˆë‹¤.

# -------------------------------
# 1. YOLO ëª¨ë¸ ë¡œë“œ
# -------------------------------
# í•™ìŠµëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê°€ì¤‘ì¹˜(.pt) ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì ì¬
model = YOLO("../weights/best.pt")

# í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜
# YOLO ê²°ê³¼(result.boxes.cls)ëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë‚˜ì˜¤ë¯€ë¡œ, ì´ë¦„ìœ¼ë¡œ ë³€í™˜
CLASS_NAMES = {0: 'wood', 1: 'vinyl', 2: 'plastic'}
CLASS_LIST = ['wood', 'vinyl', 'plastic']

# -------------------------------
# 2. YOLO íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------
def extract_ratios(image_path):
    """
        ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•´ YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•˜ê³ ,
        ê° í´ë˜ìŠ¤(wood, vinyl, plastic)ê°€ ì°¨ì§€í•˜ëŠ” 'ë§ˆìŠ¤í¬ í”½ì…€ ìˆ˜ / ì „ì²´ í”½ì…€ ìˆ˜' ë¹„ìœ¨ì„ ë°˜í™˜
        ë°˜í™˜: [wood_ratio, vinyl_ratio, plastic_ratio] (ê° 0~1 ì‹¤ìˆ˜)
        ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    """
    # YOLO ì¶”ë¡  (UltralyticsëŠ” ê²½ë¡œ ë¬¸ìì—´ì„ ë°”ë¡œ ë„£ì–´ë„ ë‚´ë¶€ì—ì„œ ì½ì–´ ì²˜ë¦¬ ê°€ëŠ¥)
    results = model(image_path)

    # OpenCVë¡œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì½ì–´ í¬ê¸°(í”½ì…€ ìˆ˜)ë¥¼ êµ¬í•¨
    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        return None

    h, w, _ = img.shape
    total_area = h * w  # ì „ì²´ í”½ì…€ ìˆ˜

    # í´ë˜ìŠ¤ë³„ ëˆ„ì  ë©´ì (í”½ì…€ ìˆ˜) ì´ˆê¸°í™”
    class_areas = {name: 0 for name in CLASS_LIST}

    for result in results:
        masks = result.masks    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ê°ì²´
        if masks is None:       # í•´ë‹¹ ì´ë¯¸ì§€ì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ 1ê°œë„ ì•ˆ ì¡íŒ ê²½ìš°
            continue

        # masks.data: shape = [N, H, W], ê°’ì€ 0/1(ë˜ëŠ” 0.0/1.0) float í…ì„œ
        # result.boxes.cls: ê¸¸ì´ N, ê° ì¸ìŠ¤í„´ìŠ¤ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        for mask, cls in zip(masks.data, result.boxes.cls):
            # ë””ë²„ê¹…ìš© ì¶œë ¥: ë§ˆìŠ¤í¬ í…ì„œ í¬ê¸°ì™€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
            print("ë§ˆìŠ¤í¬ í…ì„œ í¬ê¸°ì™€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤")
            print(mask.shape, cls)

            # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
            cls_name = CLASS_NAMES[int(cls)]

            # í…ì„œ â†’ NumPy â†’ uint8(0/1)ë¡œ ë³€í™˜ í›„ í”½ì…€ í•©ì‚°
            mask_np = mask.cpu().numpy().astype(np.uint8)
            class_areas[cls_name] += np.sum(mask_np)

    # ê° í´ë˜ìŠ¤ ë©´ì ì„ ì „ì²´ ë©´ì (total_area)ë¡œ ë‚˜ëˆ  ë¹„ìœ¨ë¡œ ë³€í™˜
    return [
        class_areas['wood'] / total_area,
        class_areas['vinyl'] / total_area,
        class_areas['plastic'] / total_area
    ]

# -------------------------------
# 3. ê¸°ì¤€ ë°ì´í„°ì…‹ ë¡œë“œ ë° íŠ¹ì§• ì¶”ì¶œ
# -------------------------------
dataset_dir = "C:/Users/301/Desktop/pca_image"
features = []
labels = []

for cls_index, cls_name in CLASS_NAMES.items():
    class_folder = os.path.join(dataset_dir, cls_name)

    # í´ë”ê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜ (ê°œì„ â‘ )
    if not os.path.isdir(class_folder):
        print(f"âš ï¸ ê²½ê³ : í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {class_folder}")
        continue

    for filename in os.listdir(class_folder):
        if filename.lower().endswith(('.jpg', '.png')):
            img_path = os.path.join(class_folder, filename)
            ratios = extract_ratios(img_path)

            if ratios is not None:
                features.append(ratios)
                labels.append(cls_name)

features = np.array(features)   # shape: [num_samples, 3]
labels = np.array(labels)       # shape: [num_samples]

print("âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ:", features.shape)

# -------------------------------
# 4. í‘œì¤€í™” + PCA í•™ìŠµ
# -------------------------------
# PCAëŠ” ë³€ìˆ˜ ìŠ¤ì¼€ì¼ì˜ ì˜í–¥ì„ ë§ì´ ë°›ìŠµë‹ˆë‹¤.
# í´ë˜ìŠ¤ë³„ ë©´ì  ë¹„ìœ¨ì´ë¼ë„ ë¶„í¬ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í‰ê· 0/í‘œì¤€í¸ì°¨1ë¡œ í‘œì¤€í™” í›„ PCAë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
scaler = StandardScaler()
features_std = scaler.fit_transform(features)   # Z-ì •ê·œí™”(í‘œì¤€í™”) ì ìš©

# ì£¼ì„±ë¶„ 2ê°œ(2ì°¨ì›)ë¡œ ì¶•ì†Œ
pca = PCA(n_components=2)
pca_result = pca.fit_transform(features_std)

# ê° ì£¼ì„±ë¶„ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚° ë¹„ìœ¨ (í•©ê³„ëŠ” 1.0ì— ê·¼ì‚¬)
explained = pca.explained_variance_ratio_
print(f"ğŸ“Œ PCA ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨ (Standardized): {explained}")

# -------------------------------
# 5. ì €ì¥
# -------------------------------
os.makedirs("pca", exist_ok=True)

joblib.dump(pca, "pca/pca_model.pkl")
joblib.dump(scaler, "pca/scaler.pkl")    # í‘œì¤€í™” ìŠ¤ì¼€ì¼ëŸ¬

# ë¶„ì„ ì¤‘ê°„ ì‚°ì¶œë¬¼ ì €ì¥(ì„ íƒì ì´ì§€ë§Œ ì¬í˜„ì„±/ë””ë²„ê¹…ì— ìœ ìš©)
np.save("pca/features.npy", features)            # ì›ë³¸ ë¹„ìœ¨ íŠ¹ì§•(í‘œì¤€í™” ì „)
np.save("pca/features_std.npy", features_std)    # í‘œì¤€í™”ëœ íŠ¹ì§•
np.save("pca/labels.npy", labels)                # ë ˆì´ë¸”
np.save("pca/pca_explained.npy", explained)      # ì„¤ëª…ëœ ë¶„ì‚°ë¹„ìœ¨

print("âœ… í‘œì¤€í™” + PCA ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")